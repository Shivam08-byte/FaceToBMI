{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitf2bconda1887e22467f64f0497eae62b7c5e5f5e",
   "display_name": "Python 3.7.6 64-bit ('f2b': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\n"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models, utils\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from glob import glob\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from collections import OrderedDict\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Annotation data:  1026\n"
    }
   ],
   "source": [
    "annotation_df = pd.read_csv(data_path+'annotation.csv')\n",
    "annotation_df.head()\n",
    "print(\"Annotation data: \",len(annotation_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total 1026 photos \n"
    }
   ],
   "source": [
    "all_files = glob(data_path+\"images/*\")\n",
    "all_jpgs = sorted([img for img in all_files if \".jpg\" in img or \".jpeg\" in img or \"JPG\" in img])\n",
    "print(\"Total {} photos \".format(len(all_jpgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_path = [image for image in all_jpgs ]\n",
    "image_df = pd.DataFrame(id_path, columns=['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = image_dataframe.merge(profile_dataframe, left_index=True, right_index=True)\n",
    "full_df.head()\n",
    "full_df.to_csv(\"../data/interim/full_annotation.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Image path: ../data/raw/images/f_066.jpg\nImage name: f_066\nValues shape: (1, 3)\nheight: 1.77 m, weight: 55.0 kg, bmi: 17.55561939\n"
    }
   ],
   "source": [
    "n = 65\n",
    "image_path = full_df.iloc[n, 0]\n",
    "image_name = full_df.iloc[n, 1]\n",
    "values = np.asarray(full_df.iloc[n, 2:])\n",
    "values = values.astype('float').reshape(-1, 3)\n",
    "\n",
    "print('Image path: {}'.format(image_path))\n",
    "print('Image name: {}'.format(image_name))\n",
    "print('Values shape: {}'.format(values.shape))\n",
    "print('height: {} m, weight: {} kg, bmi: {}'.format(*values[:, 0], *values[:, 1], *values[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class FaceToBMIDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.annotaion = pd.read_csv(csv_file)\n",
    "        self.image_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotaion)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.image_dir, self.annotaion.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        values = self.values_frame.iloc[idx, 1:]\n",
    "        values = np.array([values])\n",
    "        values = values.astype('float').reshape(-1, 3)\n",
    "        item = {'image': image, 'values': values}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  }
 ]
}